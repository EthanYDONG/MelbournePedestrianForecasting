{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import string\n",
    "import mtscluster\n",
    "from tslearn.metrics import dtw, dtw_path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import kmedoids\n",
    "import matplotlib.pyplot as plt \n",
    "import ruptures as rpt  \n",
    "from ruptures.metrics import hausdorff\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Folder_Path = r'../datafolder'     \n",
    "SaveFile_Path =  r'melped'       \n",
    "SaveFile_Name = r'meldata19.csv'              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Folder_Path)\n",
    "file_list = os.listdir()\n",
    "\n",
    "df4 = pd.read_csv(Folder_Path +'/'+'April_2019.csv')   \n",
    "df5 = pd.read_csv(Folder_Path +'/'+'May_2019.csv')\n",
    "df6 = pd.read_csv(Folder_Path +'/'+'June_2019.csv')\n",
    "df7 = pd.read_csv(Folder_Path +'/'+'July_2019.csv')\n",
    "df8 = pd.read_csv(Folder_Path +'/'+'August_2019.csv')\n",
    "df9 = pd.read_csv(Folder_Path +'/'+'September_2019.csv')\n",
    "df10 = pd.read_csv(Folder_Path +'/'+'October_2019.csv')\n",
    "df11 = pd.read_csv(Folder_Path +'/'+'November_2019.csv')\n",
    "df12 = pd.read_csv(Folder_Path +'/'+'December_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([df4, df5,df6,df7,df8,df9,df10,df11,df12], join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldel = []\n",
    "for i,x in enumerate(temp.columns):\n",
    "    if len(temp[temp[x]==-1])>66:\n",
    "        coldel.append(x)\n",
    "print(len(coldel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnow = temp.drop(coldel,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnan = dfnow.replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldel2 = []\n",
    "for i,x in enumerate(dfnan.columns):\n",
    "    for j in range(dfnan.shape[0]):\n",
    "        if dfnan.iat[j,i] == \"undefined\":\n",
    "            coldel2.append(x)\n",
    "            break\n",
    "coldel2.append('Collins St (North)')\n",
    "print(coldel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnan = dfnan.drop(coldel2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnan = dfnan.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = list(dfnan.columns)\n",
    "streetname = colname[2:]\n",
    "mtd = ['mean']*(len(streetname))\n",
    "dict1 = dict(zip(streetname,mtd))\n",
    "print('len(streetname): ',len(streetname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanbyhour = dfnan.groupby('Hour').agg(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in streetname:\n",
    "    for i in range(dfnan.shape[0]):\n",
    "        if np.isnan(dfnan[column][i]):\n",
    "            dfnan.loc[i,column] = meanbyhour.loc[(i%24),column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfarray = dfnan.iloc[:,2:].to_numpy()\n",
    "scaler = MinMaxScaler()\n",
    "dfarray = scaler.fit_transform(dfarray)\n",
    "weeks = []\n",
    "for i in range(len(dfarray)//(24*7)):\n",
    "    weeks.append(dfarray[i*(24*7):(i+1)*(24*7),:])\n",
    "Train_data = np.array(weeks)\n",
    "\n",
    "tsdistances = np.zeros((np.shape(Train_data)[0],np.shape(Train_data)[0]))\n",
    "for ind,i in enumerate(Train_data):\n",
    "    for c_ind,j in enumerate(Train_data):\n",
    "        cur_dist = 0.0\n",
    "        #Find sum of distances along each dimension\n",
    "        for z in range(np.shape(Train_data)[2]):\n",
    "            cur_dist += dtw(i[:,z],j[:,z])\n",
    "        tsdistances[ind,c_ind] = cur_dist\n",
    "#print('Distances calculated: ', tsdistances)\n",
    "#pd.DataFrame(tsdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result =  kmedoids.pam(tsdistances, 2, max_iter=1000, init='random', random_state=None)\n",
    "cluster_result.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsdisframe = pd.DataFrame(tsdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_first = []\n",
    "dis_second = []\n",
    "\n",
    "for i in range(len(tsdistances)):\n",
    "    if cluster_result.labels[i] == 1:\n",
    "        dis_second.append(clsdisframe.iloc[i,cluster_result.medoids[1]])\n",
    "    else:\n",
    "        dis_first.append(clsdisframe.iloc[i,cluster_result.medoids[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropedge1 = np.percentile(np.array(dis_first), 75)+1.5*(np.percentile(np.array(dis_first), 75)-np.percentile(np.array(dis_first), 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropedge2 = np.percentile(np.array(dis_second), 75)+1.5*(np.percentile(np.array(dis_second), 75)-np.percentile(np.array(dis_second), 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medo_iter = []\n",
    "for i in range(1000):\n",
    "    clusters, curr_medoids = mtscluster.cluster(tsdistances, 2)\n",
    "    # print('Mediods are :')\n",
    "    # print(curr_medoids)\n",
    "    # print('Cluster assigments : ')\n",
    "    # print(clusters)\n",
    "    medo_iter.append(curr_medoids)\n",
    "medo_iter = [l.tolist() for l in medo_iter]\n",
    "for l in medo_iter:\n",
    "    l.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "     \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    " \n",
    "    return num\n",
    " \n",
    "List = medo_iter\n",
    "clsdistance = pd.DataFrame(tsdistances).iloc[:,most_frequent(List)]\n",
    "clsdistance['sum'] = clsdistance.iloc[:,0]+clsdistance.iloc[:,1]\n",
    "clsdistance = clsdistance.sort_values(by=['sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dissum = clsdistance['sum'].to_numpy() \n",
    "dropedge = np.percentile(dissum, 75)+1.5*(np.percentile(dissum, 75)-np.percentile(dissum, 25))\n",
    "weekdrop = clsdistance[clsdistance['sum']>dropedge].index.to_list()\n",
    "dfgood = dfnan.iloc[4*24*7:38*24*7,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = copy.deepcopy(dfgood.iloc[:168,2:])\n",
    "df_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,27):   \n",
    "    df_initial+=dfgood.iloc[i*168:(i+1)*168,2:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = df_initial/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcomplete = copy.deepcopy(dfgood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(len(dfcomplete)/168)):\n",
    "    dfcomplete.iloc[i*168:(i+1)*168,2:] = dfcomplete.iloc[i*168:(i+1)*168,2:].reset_index(drop=True)-df_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcenter = dfnan.iloc[7*24*7:8*24*7,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcenterall = dfcenter.iloc[:,2:].to_numpy()\n",
    "scaler = MinMaxScaler()\n",
    "dfcentertrain = scaler.fit_transform(dfcenterall)\n",
    "\n",
    "tsdistancesall = np.zeros((np.shape(dfcentertrain)[1],np.shape(dfcentertrain)[1]))\n",
    "for i in range(dfcentertrain.shape[1]):\n",
    "    for j in range(dfcentertrain.shape[1]):\n",
    "        tsdistancesall[i,j] = dtw(dfcentertrain[:,i],dfcentertrain[:,j])  \n",
    "#print('Distances calculated: ', tsdistances)\n",
    "#pd.DataFrame(tsdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfday = np.zeros([24,30])\n",
    "for i in range(7):\n",
    "    dfday = dfday+dfcenter.iloc[:,2:].iloc[i*24:(i+1)*24,:].to_numpy()\n",
    "dfday = dfday/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationdata = pd.read_csv('../datafolder/Pedestrian_Counting_System_-_Sensor_Locations.csv')\n",
    "locationdata = locationdata[['sensor_description','latitude','longitude']]\n",
    "locationdata.set_index('sensor_description', inplace=True)\n",
    "locationdata = locationdata.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streetdata = locationdata[streetname] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationdata = pd.read_csv('/data/dyw/melped/Pedestrian_Counting_System_-_Sensor_Locations.csv')\n",
    "stationdata = stationdata[['sensor_description','latitude','longitude']]\n",
    "stationdata.set_index('sensor_description', inplace=True)\n",
    "stationdata = stationdata.T\n",
    "\n",
    "stationdf = pd.concat([stationdata['Southern Cross Station'],stationdata['Flinders Street Station Underpass'],stationdata['Flagstaff Station'],stationdata['Melbourne Central'],stationdata['Collins Place (South)']],axis=1)\n",
    "staname = list(stationdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationdistmat = pd.DataFrame(np.zeros((len(staname),len(streetname))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sta in enumerate(staname):\n",
    "    for j,stre in enumerate(streetname):\n",
    "        stationdistmat.iloc[i,j]=(np.sqrt((streetdata[stre][0]-stationdf[sta][0])**2+(streetdata[stre][1]-stationdf[sta][1])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationminmat =  stationdistmat.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadistlist = []\n",
    "stasensorfrom = []\n",
    "stasensorto = []\n",
    "for ifrom,istree in enumerate(streetname):\n",
    "    for jto,jstree in enumerate(streetname):\n",
    "        stasensorfrom.append(istree)\n",
    "        stasensorto.append(jstree)\n",
    "        stadistlist.append(np.abs((stationminmat[ifrom]-stationminmat[jto])))\n",
    "# print(sensorfrom)\n",
    "# print(sensorto)\n",
    "# print(distlist[31])\n",
    "stadistancedict = {'from':stasensorfrom,'to':stasensorto, 'dist': stadistlist}\n",
    "stadistance_df0 = pd.DataFrame(stadistancedict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdistlist = []\n",
    "tssensorfrom = []\n",
    "tssensorto = []\n",
    "for ifrom,istree in enumerate(streetname):\n",
    "    for jto,jstree in enumerate(streetname):\n",
    "        tssensorfrom.append(istree)\n",
    "        tssensorto.append(jstree)\n",
    "        tsdistlist.append(tsdistancesall[ifrom,jto])\n",
    "# print(sensorfrom)\n",
    "# print(sensorto)\n",
    "# print(distlist[31])\n",
    "tsdistancedict = {'from':tssensorfrom,'to':tssensorto, 'dist': tsdistlist}\n",
    "tsdistance_df0 = pd.DataFrame(tsdistancedict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distlist = []\n",
    "sensorfrom = []\n",
    "sensorto = []\n",
    "for ifrom in streetname:\n",
    "    for jto in streetname:\n",
    "        sensorfrom.append(ifrom)\n",
    "        sensorto.append(jto)\n",
    "        distlist.append(np.sqrt((streetdata[ifrom][0]-streetdata[jto][0])**2+(streetdata[ifrom][1]-streetdata[jto][1])**2))\n",
    "# print(sensorfrom)\n",
    "# print(sensorto)\n",
    "# print(distlist[31])\n",
    "distancedict = {'from':sensorfrom,'to':sensorto, 'dist': distlist}\n",
    "distance_df0 = pd.DataFrame(distancedict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix(distance_df, sensor_ids, normalized_k=0.1):\n",
    "    \"\"\"\n",
    "    :param distance_df: data frame with three columns: [from, to, distance].\n",
    "    :param sensor_ids: list of sensor ids.\n",
    "    :param normalized_k: entries that become lower than normalized_k after normalization are set to zero for sparsity.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_sensors = len(sensor_ids)\n",
    "    dist_mx = np.zeros((num_sensors, num_sensors), dtype=np.float32)\n",
    "    dist_mx[:] = np.inf\n",
    "    # Builds sensor id to index map.\n",
    "    sensor_id_to_ind = {}\n",
    "    for i, sensor_id in enumerate(sensor_ids):\n",
    "        sensor_id_to_ind[sensor_id] = i\n",
    "\n",
    "    # Fills cells in the matrix with distances.\n",
    "    for row in distance_df.values:\n",
    "        if row[0] not in sensor_id_to_ind or row[1] not in sensor_id_to_ind:\n",
    "            continue\n",
    "        dist_mx[sensor_id_to_ind[row[0]], sensor_id_to_ind[row[1]]] = row[2]\n",
    "\n",
    "    # Calculates the standard deviation as theta.\n",
    "    distances = dist_mx[~np.isinf(dist_mx)].flatten()\n",
    "    std = distances.std()\n",
    "    adj_mx = np.exp(-np.square(dist_mx / std))\n",
    "    # Make the adjacent matrix symmetric by taking the max.\n",
    "    # adj_mx = np.maximum.reduce([adj_mx, adj_mx.T])\n",
    "\n",
    "    # Sets entries that lower than a threshold, i.e., k, to zero for sparsity.\n",
    "    adj_mx[adj_mx < normalized_k] = 0\n",
    "    return sensor_ids, sensor_id_to_ind, adj_mx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance matrix based on latitude and longtitude\n",
    "sensor_ids0, sensor_id_to_ind0, adj_mx0 = get_adjacency_matrix(distance_df0,streetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance matrix based on time series similarity\n",
    "tmsensor_ids0, tmsensor_id_to_ind0, tm_adj_mx0 = get_adjacency_matrix(tsdistance_df0,streetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # distance matrix based on minimum distance to train station\n",
    "# stasensor_ids0, stasensor_id_to_ind0, sta_adj_mx0 =  get_adjacency_matrix(stadistance_df0,streetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjmat0001 = adj_mx0 + 0.001*tm_adj_mx0\n",
    "adjmat001 = adj_mx0 + 0.01*tm_adj_mx0\n",
    "adjmat002 = adj_mx0 + 0.02*tm_adj_mx0\n",
    "adjmat005 = adj_mx0 + 0.05*tm_adj_mx0\n",
    "adjmat01 = adj_mx0 + 0.1*tm_adj_mx0\n",
    "adjmat02 = adj_mx0 + 0.2*tm_adj_mx0\n",
    "adjmat05 = adj_mx0 + 0.5*tm_adj_mx0\n",
    "adjmat1 = adj_mx0 + tm_adj_mx0\n",
    "adjmat2 = adj_mx0 + 2*tm_adj_mx0\n",
    "adjmat5 = adj_mx0 + 5*tm_adj_mx0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat.pkl', 'wb') as f:\n",
    "    pickle.dump([sensor_ids0, sensor_id_to_ind0, adj_mx0], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat0001.pkl', 'wb') as f:\n",
    "    pickle.dump([sensor_ids0, sensor_id_to_ind0, adjmat0001], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat001.pkl', 'wb') as f:\n",
    "    pickle.dump([tmsensor_ids0, tmsensor_id_to_ind0, adjmat001], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat002.pkl', 'wb') as f:\n",
    "    pickle.dump([tmsensor_ids0, tmsensor_id_to_ind0, adjmat002], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat005.pkl', 'wb') as f:\n",
    "    pickle.dump([tmsensor_ids0, tmsensor_id_to_ind0, adjmat005], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat01.pkl', 'wb') as f:\n",
    "    pickle.dump([tmsensor_ids0, tmsensor_id_to_ind0, adjmat01], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat02.pkl', 'wb') as f:\n",
    "    pickle.dump([tmsensor_ids0, tmsensor_id_to_ind0, adjmat02], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat05.pkl', 'wb') as f:\n",
    "    pickle.dump([tmsensor_ids0, tmsensor_id_to_ind0, adjmat05], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat1.pkl', 'wb') as f:\n",
    "    pickle.dump([tmsensor_ids0, tmsensor_id_to_ind0, adjmat1], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat2.pkl', 'wb') as f:\n",
    "    pickle.dump([tmsensor_ids0, tmsensor_id_to_ind0, adjmat2], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adjmat5.pkl', 'wb') as f:\n",
    "    pickle.dump([tmsensor_ids0, tmsensor_id_to_ind0, adjmat5], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgood['Hour'] = dfgood['Hour'].apply(str)\n",
    "dfgood['Time'] = dfgood['Date']+' '+dfgood['Hour']\n",
    "dfgood2=dfgood[['Time']+streetname]\n",
    "dfgood2['Time'] = pd.to_datetime(dfgood2['Time'], format=\"%d/%m/%Y %H\")\n",
    "dfgoodclean = dfgood2[streetname]\n",
    "dfgoodclean.index = list(dfgood2['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgoodclean.to_hdf(f'meldatagood.h5', key='dfgoodclean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the DCRNN part, see https://github.com/xlwang233/pytorch-DCRNN "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbc4df2d6b5c3196fcd665d8251157c1a0ed56638c0efdd8890ce8658232a632"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
